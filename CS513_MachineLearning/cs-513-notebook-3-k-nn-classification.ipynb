{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c4b90b",
   "metadata": {
    "papermill": {
     "duration": 0.012394,
     "end_time": "2023-04-21T05:52:20.778418",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.766024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains two parts. **Part 1, Evaluating k-NN Classifiers**, provides you an opportunity to demonstrate your ability to apply course concepts to determine the ideal **_k_** for a k-NN Classifier on a contrived Iris data set. **Part 2, Classifying Handwritten Digits**, provides you an opportunity to practice using widely-used ML libraries and an ML workflow to solve a classification problem.\n",
    "\n",
    "You do not need to complete Part 1 in order to complete Part 2. If you get stuck on Part 1, and choose to work on Part 2, be sure that all of your code for Part 1 runs without error. You can comment out your code in Part 1 if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ece792",
   "metadata": {
    "papermill": {
     "duration": 0.010659,
     "end_time": "2023-04-21T05:52:20.800334",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.789675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1: Evaluating k-NN Classifiers\n",
    "\n",
    "Given a simple KnnClassifier, and a complete data set of [Iris attributes](https://www.kaggle.com/datasets/uciml/iris), demonstrate your ability to:\n",
    "\n",
    "1. Split a data set into appropriate training and test sets\n",
    "2. \"Train\" a k-NN classifier\n",
    "3. Repeatedly test a k-NN classifier, and collect generalization errors\n",
    "4. Analyze the generalization error for different values of `k`\n",
    "5. Identify the ideal `k` value for this classifier\n",
    "\n",
    "## The Classifier Implementation\n",
    "\n",
    "Let's first introduce the classifier, which you should find familiar, and you do not need to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30594aaa",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:20.825569Z",
     "iopub.status.busy": "2023-04-21T05:52:20.824359Z",
     "iopub.status.idle": "2023-04-21T05:52:20.841697Z",
     "shell.execute_reply": "2023-04-21T05:52:20.840760Z"
    },
    "papermill": {
     "duration": 0.033036,
     "end_time": "2023-04-21T05:52:20.844396",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.811360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A simple KnnClassifier. Uses Euclidean distance.\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "class KnnClassifier:\n",
    "\n",
    "    def __init__(self, k = 1):\n",
    "        self.k = k\n",
    "\n",
    "    def train(self, training_set):\n",
    "        self.training_set = training_set\n",
    "\n",
    "    def test(self, test_set):\n",
    "        number_of_correct_predictions = 0\n",
    "        for example in test_set:\n",
    "            prediction = self.predict(example[:-1])\n",
    "            if prediction == example[-1]:\n",
    "                number_of_correct_predictions += 1\n",
    "        return number_of_correct_predictions / len(test_set)\n",
    "\n",
    "    def predict(self, x):\n",
    "        distances = {}\n",
    "        for training_instance in self.training_set:\n",
    "            distance = self._distance(training_instance[:-1], x)\n",
    "            distances[distance] = training_instance[-1]\n",
    "        k_nearest_keys = sorted(list(distances.keys()))[:self.k]\n",
    "        k_nearest_labels = [distances[key] for key in k_nearest_keys]\n",
    "        label_frequencies = {label:k_nearest_labels.count(label) for label in k_nearest_labels}\n",
    "        frequencies = list(label_frequencies.values())\n",
    "        labels = list(label_frequencies.keys())\n",
    "        return labels[frequencies.index(max(frequencies))]\n",
    "\n",
    "    def _distance(self, training_instance, x):\n",
    "        sum_of_squares = 0\n",
    "        for i in range(len(x)):\n",
    "            sum_of_squares += (x[i] - training_instance[i])**2\n",
    "        return \"%.5f\" % sqrt(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af43684",
   "metadata": {
    "papermill": {
     "duration": 0.012438,
     "end_time": "2023-04-21T05:52:20.868007",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.855569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Data Set\n",
    "\n",
    "There is no need for you to manually load the data set. We have provided the classic Iris data set here as a two-dimensional Python list, where each sub-list represents the attributes for one flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18e44c4e",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:20.893397Z",
     "iopub.status.busy": "2023-04-21T05:52:20.892438Z",
     "iopub.status.idle": "2023-04-21T05:52:20.929030Z",
     "shell.execute_reply": "2023-04-21T05:52:20.927755Z"
    },
    "papermill": {
     "duration": 0.052854,
     "end_time": "2023-04-21T05:52:20.932201",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.879347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris_data_set = [\n",
    "    [5.1,3.5,1.4,0.2,'Iris-setosa'],\n",
    "    [4.9,3.0,1.4,0.2,'Iris-setosa'],\n",
    "    [4.7,3.2,1.3,0.2,'Iris-setosa'],\n",
    "    [4.6,3.1,1.5,0.2,'Iris-setosa'],\n",
    "    [5.0,3.6,1.4,0.2,'Iris-setosa'],\n",
    "    [5.4,3.9,1.7,0.4,'Iris-setosa'],\n",
    "    [4.6,3.4,1.4,0.3,'Iris-setosa'],\n",
    "    [5.0,3.4,1.5,0.2,'Iris-setosa'],\n",
    "    [4.4,2.9,1.4,0.2,'Iris-setosa'],\n",
    "    [4.9,3.1,1.5,0.1,'Iris-setosa'],\n",
    "    [5.4,3.7,1.5,0.2,'Iris-setosa'],\n",
    "    [4.8,3.4,1.6,0.2,'Iris-setosa'],\n",
    "    [4.8,3.0,1.4,0.1,'Iris-setosa'],\n",
    "    [4.3,3.0,1.1,0.1,'Iris-setosa'],\n",
    "    [5.8,4.0,1.2,0.2,'Iris-setosa'],\n",
    "    [5.7,4.4,1.5,0.4,'Iris-setosa'],\n",
    "    [5.4,3.9,1.3,0.4,'Iris-setosa'],\n",
    "    [5.1,3.5,1.4,0.3,'Iris-setosa'],\n",
    "    [5.7,3.8,1.7,0.3,'Iris-setosa'],\n",
    "    [5.1,3.8,1.5,0.3,'Iris-setosa'],\n",
    "    [5.4,3.4,1.7,0.2,'Iris-setosa'],\n",
    "    [5.1,3.7,1.5,0.4,'Iris-setosa'],\n",
    "    [4.6,3.6,1.0,0.2,'Iris-setosa'],\n",
    "    [5.1,3.3,1.7,0.5,'Iris-setosa'],\n",
    "    [4.8,3.4,1.9,0.2,'Iris-setosa'],\n",
    "    [5.0,3.0,1.6,0.2,'Iris-setosa'],\n",
    "    [5.0,3.4,1.6,0.4,'Iris-setosa'],\n",
    "    [5.2,3.5,1.5,0.2,'Iris-setosa'],\n",
    "    [5.2,3.4,1.4,0.2,'Iris-setosa'],\n",
    "    [4.7,3.2,1.6,0.2,'Iris-setosa'],\n",
    "    [4.8,3.1,1.6,0.2,'Iris-setosa'],\n",
    "    [5.4,3.4,1.5,0.4,'Iris-setosa'],\n",
    "    [5.2,4.1,1.5,0.1,'Iris-setosa'],\n",
    "    [5.5,4.2,1.4,0.2,'Iris-setosa'],\n",
    "    [4.9,3.1,1.5,0.1,'Iris-setosa'],\n",
    "    [5.0,3.2,1.2,0.2,'Iris-setosa'],\n",
    "    [5.5,3.5,1.3,0.2,'Iris-setosa'],\n",
    "    [4.9,3.1,1.5,0.1,'Iris-setosa'],\n",
    "    [4.4,3.0,1.3,0.2,'Iris-setosa'],\n",
    "    [5.1,3.4,1.5,0.2,'Iris-setosa'],\n",
    "    [5.0,3.5,1.3,0.3,'Iris-setosa'],\n",
    "    [4.5,2.3,1.3,0.3,'Iris-setosa'],\n",
    "    [4.4,3.2,1.3,0.2,'Iris-setosa'],\n",
    "    [5.0,3.5,1.6,0.6,'Iris-setosa'],\n",
    "    [5.1,3.8,1.9,0.4,'Iris-setosa'],\n",
    "    [4.8,3.0,1.4,0.3,'Iris-setosa'],\n",
    "    [5.1,3.8,1.6,0.2,'Iris-setosa'],\n",
    "    [4.6,3.2,1.4,0.2,'Iris-setosa'],\n",
    "    [5.3,3.7,1.5,0.2,'Iris-setosa'],\n",
    "    [5.0,3.3,1.4,0.2,'Iris-setosa'],\n",
    "    [7.0,3.2,4.7,1.4,'Iris-versicolor'],\n",
    "    [6.4,3.2,4.5,1.5,'Iris-versicolor'],\n",
    "    [6.9,3.1,4.9,1.5,'Iris-versicolor'],\n",
    "    [5.5,2.3,4.0,1.3,'Iris-versicolor'],\n",
    "    [6.5,2.8,4.6,1.5,'Iris-versicolor'],\n",
    "    [5.7,2.8,4.5,1.3,'Iris-versicolor'],\n",
    "    [6.3,3.3,4.7,1.6,'Iris-versicolor'],\n",
    "    [4.9,2.4,3.3,1.0,'Iris-versicolor'],\n",
    "    [6.6,2.9,4.6,1.3,'Iris-versicolor'],\n",
    "    [5.2,2.7,3.9,1.4,'Iris-versicolor'],\n",
    "    [5.0,2.0,3.5,1.0,'Iris-versicolor'],\n",
    "    [5.9,3.0,4.2,1.5,'Iris-versicolor'],\n",
    "    [6.0,2.2,4.0,1.0,'Iris-versicolor'],\n",
    "    [6.1,2.9,4.7,1.4,'Iris-versicolor'],\n",
    "    [5.6,2.9,3.6,1.3,'Iris-versicolor'],\n",
    "    [6.7,3.1,4.4,1.4,'Iris-versicolor'],\n",
    "    [5.6,3.0,4.5,1.5,'Iris-versicolor'],\n",
    "    [5.8,2.7,4.1,1.0,'Iris-versicolor'],\n",
    "    [6.2,2.2,4.5,1.5,'Iris-versicolor'],\n",
    "    [5.6,2.5,3.9,1.1,'Iris-versicolor'],\n",
    "    [5.9,3.2,4.8,1.8,'Iris-versicolor'],\n",
    "    [6.1,2.8,4.0,1.3,'Iris-versicolor'],\n",
    "    [6.3,2.5,4.9,1.5,'Iris-versicolor'],\n",
    "    [6.1,2.8,4.7,1.2,'Iris-versicolor'],\n",
    "    [6.4,2.9,4.3,1.3,'Iris-versicolor'],\n",
    "    [6.6,3.0,4.4,1.4,'Iris-versicolor'],\n",
    "    [6.8,2.8,4.8,1.4,'Iris-versicolor'],\n",
    "    [6.7,3.0,5.0,1.7,'Iris-versicolor'],\n",
    "    [6.0,2.9,4.5,1.5,'Iris-versicolor'],\n",
    "    [5.7,2.6,3.5,1.0,'Iris-versicolor'],\n",
    "    [5.5,2.4,3.8,1.1,'Iris-versicolor'],\n",
    "    [5.5,2.4,3.7,1.0,'Iris-versicolor'],\n",
    "    [5.8,2.7,3.9,1.2,'Iris-versicolor'],\n",
    "    [6.0,2.7,5.1,1.6,'Iris-versicolor'],\n",
    "    [5.4,3.0,4.5,1.5,'Iris-versicolor'],\n",
    "    [6.0,3.4,4.5,1.6,'Iris-versicolor'],\n",
    "    [6.7,3.1,4.7,1.5,'Iris-versicolor'],\n",
    "    [6.3,2.3,4.4,1.3,'Iris-versicolor'],\n",
    "    [5.6,3.0,4.1,1.3,'Iris-versicolor'],\n",
    "    [5.5,2.5,4.0,1.3,'Iris-versicolor'],\n",
    "    [5.5,2.6,4.4,1.2,'Iris-versicolor'],\n",
    "    [6.1,3.0,4.6,1.4,'Iris-versicolor'],\n",
    "    [5.8,2.6,4.0,1.2,'Iris-versicolor'],\n",
    "    [5.0,2.3,3.3,1.0,'Iris-versicolor'],\n",
    "    [5.6,2.7,4.2,1.3,'Iris-versicolor'],\n",
    "    [5.7,3.0,4.2,1.2,'Iris-versicolor'],\n",
    "    [5.7,2.9,4.2,1.3,'Iris-versicolor'],\n",
    "    [6.2,2.9,4.3,1.3,'Iris-versicolor'],\n",
    "    [5.1,2.5,3.0,1.1,'Iris-versicolor'],\n",
    "    [5.7,2.8,4.1,1.3,'Iris-versicolor'],\n",
    "    [6.3,3.3,6.0,2.5,'Iris-virginica'],\n",
    "    [5.8,2.7,5.1,1.9,'Iris-virginica'],\n",
    "    [7.1,3.0,5.9,2.1,'Iris-virginica'],\n",
    "    [6.3,2.9,5.6,1.8,'Iris-virginica'],\n",
    "    [6.5,3.0,5.8,2.2,'Iris-virginica'],\n",
    "    [7.6,3.0,6.6,2.1,'Iris-virginica'],\n",
    "    [4.9,2.5,4.5,1.7,'Iris-virginica'],\n",
    "    [7.3,2.9,6.3,1.8,'Iris-virginica'],\n",
    "    [6.7,2.5,5.8,1.8,'Iris-virginica'],\n",
    "    [7.2,3.6,6.1,2.5,'Iris-virginica'],\n",
    "    [6.5,3.2,5.1,2.0,'Iris-virginica'],\n",
    "    [6.4,2.7,5.3,1.9,'Iris-virginica'],\n",
    "    [6.8,3.0,5.5,2.1,'Iris-virginica'],\n",
    "    [5.7,2.5,5.0,2.0,'Iris-virginica'],\n",
    "    [5.8,2.8,5.1,2.4,'Iris-virginica'],\n",
    "    [6.4,3.2,5.3,2.3,'Iris-virginica'],\n",
    "    [6.5,3.0,5.5,1.8,'Iris-virginica'],\n",
    "    [7.7,3.8,6.7,2.2,'Iris-virginica'],\n",
    "    [7.7,2.6,6.9,2.3,'Iris-virginica'],\n",
    "    [6.0,2.2,5.0,1.5,'Iris-virginica'],\n",
    "    [6.9,3.2,5.7,2.3,'Iris-virginica'],\n",
    "    [5.6,2.8,4.9,2.0,'Iris-virginica'],\n",
    "    [7.7,2.8,6.7,2.0,'Iris-virginica'],\n",
    "    [6.3,2.7,4.9,1.8,'Iris-virginica'],\n",
    "    [6.7,3.3,5.7,2.1,'Iris-virginica'],\n",
    "    [7.2,3.2,6.0,1.8,'Iris-virginica'],\n",
    "    [6.2,2.8,4.8,1.8,'Iris-virginica'],\n",
    "    [6.1,3.0,4.9,1.8,'Iris-virginica'],\n",
    "    [6.4,2.8,5.6,2.1,'Iris-virginica'],\n",
    "    [7.2,3.0,5.8,1.6,'Iris-virginica'],\n",
    "    [7.4,2.8,6.1,1.9,'Iris-virginica'],\n",
    "    [7.9,3.8,6.4,2.0,'Iris-virginica'],\n",
    "    [6.4,2.8,5.6,2.2,'Iris-virginica'],\n",
    "    [6.3,2.8,5.1,1.5,'Iris-virginica'],\n",
    "    [6.1,2.6,5.6,1.4,'Iris-virginica'],\n",
    "    [7.7,3.0,6.1,2.3,'Iris-virginica'],\n",
    "    [6.3,3.4,5.6,2.4,'Iris-virginica'],\n",
    "    [6.4,3.1,5.5,1.8,'Iris-virginica'],\n",
    "    [6.0,3.0,4.8,1.8,'Iris-virginica'],\n",
    "    [6.9,3.1,5.4,2.1,'Iris-virginica'],\n",
    "    [6.7,3.1,5.6,2.4,'Iris-virginica'],\n",
    "    [6.9,3.1,5.1,2.3,'Iris-virginica'],\n",
    "    [5.8,2.7,5.1,1.9,'Iris-virginica'],\n",
    "    [6.8,3.2,5.9,2.3,'Iris-virginica'],\n",
    "    [6.7,3.3,5.7,2.5,'Iris-virginica'],\n",
    "    [6.7,3.0,5.2,2.3,'Iris-virginica'],\n",
    "    [6.3,2.5,5.0,1.9,'Iris-virginica'],\n",
    "    [6.5,3.0,5.2,2.0,'Iris-virginica'],\n",
    "    [6.2,3.4,5.4,2.3,'Iris-virginica'],\n",
    "    [5.9,3.0,5.1,1.8,'Iris-virginica']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a35df",
   "metadata": {
    "papermill": {
     "duration": 0.010835,
     "end_time": "2023-04-21T05:52:20.954229",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.943394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What to Do\n",
    "\n",
    "Demonstrate your understanding and ability to have synthesized course concepts by providing a walkthrough, with both code and prose, that demonstrates a simple ML workflow. Your goal is to pick an ideal **_k_** for the classifier and demonstrate a methodical justification for your selection. In the end, your work should reflect the principles seen thus far in the course.\n",
    "\n",
    "Please be sure to demonstrate:\n",
    "\n",
    "1. Splitting a data set into appropriate training and test sets\n",
    "2. \"Training\" a k-NN classifier\n",
    "3. Repeatedly testing a k-NN classifier with different values of `k`, and reporting the generalization errors for each `k`\n",
    "4. Analyzing the generalization errors for different values of `k`\n",
    "5. Identifying the ideal `k` value for this classifier, and justifying your selection by demonstrating a sound process (not just assertion)\n",
    "\n",
    "### Tips\n",
    "\n",
    "1. Be sure that you have spent time with the Exploration materials in this course.\n",
    "2. Ask questions on the course forum if you get stuck (describe what you are trying to do, and errors that you encounter)\n",
    "3. **Keep it simple.** This is more straightforward than it may initially seem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991aa475",
   "metadata": {
    "papermill": {
     "duration": 0.01077,
     "end_time": "2023-04-21T05:52:20.976121",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.965351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Splitting the data set into appropriate training and testing sets\n",
    "\n",
    "I will use a simple holdout method for splitting the data into training and testing sets. The holdout method is holding back a pre-determined portion of the randomized data for testing and using the remaining portion to train the model. A general rule of thumb among practitioners is to use 80% for training and 20% for testing. \n",
    "\n",
    "I calculated how much 20% of the data would be, and after shuffling the data with the random library from Python I used that value to split the data into testing and training data sets with list slicing. I confirmed the results by printing the lengths of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0243a7ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:21.000210Z",
     "iopub.status.busy": "2023-04-21T05:52:20.999789Z",
     "iopub.status.idle": "2023-04-21T05:52:21.008132Z",
     "shell.execute_reply": "2023-04-21T05:52:21.006624Z"
    },
    "papermill": {
     "duration": 0.024748,
     "end_time": "2023-04-21T05:52:21.011974",
     "exception": false,
     "start_time": "2023-04-21T05:52:20.987226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 30\n",
      "Training: 120\n"
     ]
    }
   ],
   "source": [
    "#import random to be able to randomly shuffle the data\n",
    "import random\n",
    "\n",
    "# Select a percentage of data to be witheld for testing\n",
    "testing_percentage = 0.2\n",
    "\n",
    "# Calculate the number of testing items needed for the specificed percentage\n",
    "testing_number = int(len(iris_data_set) * testing_percentage)\n",
    "\n",
    "# Randomly shuffle the data\n",
    "random.shuffle(iris_data_set)\n",
    "\n",
    "# Split the data into testing and training using indicies\n",
    "iris_testing_data = iris_data_set[:testing_number]\n",
    "iris_training_data = iris_data_set[testing_number:]\n",
    "\n",
    "print(\"Testing: \" + str(len(iris_testing_data)))\n",
    "print(\"Training: \" + str(len(iris_training_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37cacb",
   "metadata": {
    "papermill": {
     "duration": 0.010922,
     "end_time": "2023-04-21T05:52:21.034263",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.023341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Notice that there are 30 records for testing, and 120 records for training. That means that 20% of the data is saved for testing as is specified in the code (30 / (30 + 120) = 0.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0066e",
   "metadata": {
    "papermill": {
     "duration": 0.010917,
     "end_time": "2023-04-21T05:52:21.056513",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.045596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Testing the kNN Classifier\n",
    "\n",
    "The next step is to train and test the kNN classifier. The class \"KnnClassifier\" has already been provided above, so I just need to use the pre-defined methods. Before I can initialize the model, I must pick a k value. In the next few steps, I will iterate with several different k values to find the best one, but for now I just want to try and run the model once. It is best practice to start k as the value of the square root of the number of training records, which in this case is 11 (sqrt(120) = 10.95). After calculating this, I followed the methods to initialize, train, and test the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d26724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:21.081303Z",
     "iopub.status.busy": "2023-04-21T05:52:21.080893Z",
     "iopub.status.idle": "2023-04-21T05:52:21.097293Z",
     "shell.execute_reply": "2023-04-21T05:52:21.095952Z"
    },
    "papermill": {
     "duration": 0.031882,
     "end_time": "2023-04-21T05:52:21.099889",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.068007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Picking an intial k value. It's best practice to start with the square root of the number of training records\n",
    "k_value = round(sqrt(len(iris_training_data))) # In our case, this rounds to 11.\n",
    "\n",
    "#Intialize, train, and test the model\n",
    "kNN_model = KnnClassifier(k=k_value)\n",
    "kNN_model.train(iris_training_data) \n",
    "accuracy = kNN_model.test(iris_testing_data)\n",
    "\n",
    "#Report the accuracy\n",
    "print(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c89e7a",
   "metadata": {
    "papermill": {
     "duration": 0.010899,
     "end_time": "2023-04-21T05:52:21.122063",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.111164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The reported generalization error for a k value of 11 is 96.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933c270",
   "metadata": {
    "papermill": {
     "duration": 0.010925,
     "end_time": "2023-04-21T05:52:21.144420",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.133495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing for the ideal k\n",
    "\n",
    "Now that the model has run successfully, I will test many different values of k to find the ideal value. I will use a for loop to run k values from 1 to 63 (inclusive). I picked this as the limit because it was around half of the training set, which would not be too useful in predicting 3 different classes because each prediction would include many objects of a different class. This is also when I began to see a consistent trend toward lower accuracies, which I will discuss in the next section.\n",
    "\n",
    "I printed each k value and its generalization accuracy, which is the percent of correct classifications out of the 30 objects in the testing data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1244533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:21.169177Z",
     "iopub.status.busy": "2023-04-21T05:52:21.168767Z",
     "iopub.status.idle": "2023-04-21T05:52:21.724752Z",
     "shell.execute_reply": "2023-04-21T05:52:21.722909Z"
    },
    "papermill": {
     "duration": 0.571632,
     "end_time": "2023-04-21T05:52:21.727368",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.155736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K value of 1 accuracy: 0.9666666666666667\n",
      "K value of 2 accuracy: 0.9666666666666667\n",
      "K value of 3 accuracy: 0.9666666666666667\n",
      "K value of 4 accuracy: 0.9666666666666667\n",
      "K value of 5 accuracy: 0.9666666666666667\n",
      "K value of 6 accuracy: 0.9666666666666667\n",
      "K value of 7 accuracy: 0.9333333333333333\n",
      "K value of 8 accuracy: 0.9333333333333333\n",
      "K value of 9 accuracy: 0.9333333333333333\n",
      "K value of 10 accuracy: 0.9333333333333333\n",
      "K value of 11 accuracy: 0.9333333333333333\n",
      "K value of 12 accuracy: 0.9333333333333333\n",
      "K value of 13 accuracy: 0.9333333333333333\n",
      "K value of 14 accuracy: 0.9333333333333333\n",
      "K value of 15 accuracy: 0.9333333333333333\n",
      "K value of 16 accuracy: 0.9333333333333333\n",
      "K value of 17 accuracy: 0.9\n",
      "K value of 18 accuracy: 0.9333333333333333\n",
      "K value of 19 accuracy: 0.8666666666666667\n",
      "K value of 20 accuracy: 0.9\n",
      "K value of 21 accuracy: 0.9\n",
      "K value of 22 accuracy: 0.9\n",
      "K value of 23 accuracy: 0.9\n",
      "K value of 24 accuracy: 0.9\n",
      "K value of 25 accuracy: 0.9\n",
      "K value of 26 accuracy: 0.9\n",
      "K value of 27 accuracy: 0.9333333333333333\n",
      "K value of 28 accuracy: 0.9\n",
      "K value of 29 accuracy: 0.9333333333333333\n",
      "K value of 30 accuracy: 0.9333333333333333\n",
      "K value of 31 accuracy: 0.9333333333333333\n",
      "K value of 32 accuracy: 0.9666666666666667\n",
      "K value of 33 accuracy: 0.9\n",
      "K value of 34 accuracy: 0.9\n",
      "K value of 35 accuracy: 0.9\n",
      "K value of 36 accuracy: 0.9\n",
      "K value of 37 accuracy: 0.9\n",
      "K value of 38 accuracy: 0.9333333333333333\n",
      "K value of 39 accuracy: 0.9\n",
      "K value of 40 accuracy: 0.9333333333333333\n",
      "K value of 41 accuracy: 0.9\n",
      "K value of 42 accuracy: 0.9\n",
      "K value of 43 accuracy: 0.9\n",
      "K value of 44 accuracy: 0.9\n",
      "K value of 45 accuracy: 0.9\n",
      "K value of 46 accuracy: 0.9\n",
      "K value of 47 accuracy: 0.9\n",
      "K value of 48 accuracy: 0.9\n",
      "K value of 49 accuracy: 0.8666666666666667\n",
      "K value of 50 accuracy: 0.9\n",
      "K value of 51 accuracy: 0.9\n",
      "K value of 52 accuracy: 0.9333333333333333\n",
      "K value of 53 accuracy: 0.9\n",
      "K value of 54 accuracy: 0.8333333333333334\n",
      "K value of 55 accuracy: 0.8\n",
      "K value of 56 accuracy: 0.8333333333333334\n",
      "K value of 57 accuracy: 0.8\n",
      "K value of 58 accuracy: 0.8\n",
      "K value of 59 accuracy: 0.7666666666666667\n",
      "K value of 60 accuracy: 0.7666666666666667\n",
      "K value of 61 accuracy: 0.7333333333333333\n",
      "K value of 62 accuracy: 0.7333333333333333\n",
      "K value of 63 accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "for k_value in range(1,64):\n",
    "    \n",
    "    # Intialize, train, and test the model\n",
    "    kNN_model = KnnClassifier(k=k_value)\n",
    "    kNN_model.train(iris_training_data) \n",
    "    accuracy = kNN_model.test(iris_testing_data)\n",
    "    \n",
    "    # Report the k_value and its associated accuracy\n",
    "    print(\"K value of \" + str(k_value) + \" accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5b67e",
   "metadata": {
    "papermill": {
     "duration": 0.011996,
     "end_time": "2023-04-21T05:52:21.751338",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.739342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The accuracy bounces around from 90% to a max of 96.7% back to 90% and so on until k values reach greater than 54. At that point, there is a steady decline in accuracy, ending with an accuracy of 40% for the k value of 63. I suspect that the variability is a result of the simple method used to split the data and only perform one test. If something like stratified k-fold cross validation was used, I think the reported accuracies might be less variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e29979",
   "metadata": {
    "papermill": {
     "duration": 0.011591,
     "end_time": "2023-04-21T05:52:21.775072",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.763481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Picking the ideal k\n",
    "\n",
    "Given the results above, the ideal k is 11. It is tied with many other k values for the highest accuracy score of 96.7%. I picked 11 over the others because it is one of the lowest values with such a high accuracy. A higher k value would help the model be more stable but would increase the computation time and be less interpretable. Both 10 and 3 also had accuracies of 96.7% and were lower than 11. I did not pick a k value of only 3 because it would make the model very sensitive to outliers and noise, and I did not pick 10 because the k value of 11 was surrounded by higher accuracies (k of 10 was 96.7%, k of 12 was 93.3%). Imagining the accuracy results plotted, a k value of 11 was near the middle of the high points in the plot. I thought this suggested that given different testing and training splits, a k value of 11 would perform better more consistently. I also felt comfortable with 11 because it was the suggested starting point for a k value based on the number of training objects in the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed08fadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:21.801087Z",
     "iopub.status.busy": "2023-04-21T05:52:21.800296Z",
     "iopub.status.idle": "2023-04-21T05:52:21.815339Z",
     "shell.execute_reply": "2023-04-21T05:52:21.813806Z"
    },
    "papermill": {
     "duration": 0.030807,
     "end_time": "2023-04-21T05:52:21.817731",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.786924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# The final code\n",
    "\n",
    "# The ideal k value I decided upon\n",
    "k_value = 11\n",
    "\n",
    "#Intialize, train, and test the model\n",
    "kNN_model = KnnClassifier(k=k_value)\n",
    "kNN_model.train(iris_training_data) \n",
    "accuracy = kNN_model.test(iris_testing_data)\n",
    "\n",
    "#Report the accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da28fa2",
   "metadata": {
    "papermill": {
     "duration": 0.011936,
     "end_time": "2023-04-21T05:52:21.841722",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.829786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Write a review of what you did, some key decisions you made along the way and why you made those decisions, the end result, and what you might do next or experiment with next to achieve a higher performing classifier.\n",
    "\n",
    "### 💡 Knowledge Check Part 1\n",
    "\n",
    "In part 1, I learned how to split a data set into training and testing sets with the random library from Python. I tested k values for a kNN classifier model from 1 to 63, where I began to see a consistent drop off in accuracy values. I picked a k value of 11 because it had tied with others for the highest accuracy of 96.7% and was lower while not too low to destabilize the model. Next time, I would use a more advanced way to split the data like a stratified k-fold cross validation. This would give me a more complete view of the accuracy at each k value because each model is tested with all of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82198acf",
   "metadata": {
    "papermill": {
     "duration": 0.01147,
     "end_time": "2023-04-21T05:52:21.865100",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.853630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<!-- This cell is intentionally blank -->\n",
    "<!-- This cell is intentionally blank -->\n",
    "<!-- This cell is intentionally blank -->\n",
    "<!-- This cell is intentionally blank -->\n",
    "<!-- This cell is intentionally blank -->\n",
    "<!-- This cell is intentionally blank -->\n",
    "<!-- This cell is intentionally blank -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa1c02",
   "metadata": {
    "papermill": {
     "duration": 0.011524,
     "end_time": "2023-04-21T05:52:21.888559",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.877035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Classifying Handwritten Digits\n",
    "\n",
    "In this, the second, part of this notebook, we will build a classifier that can assign a label, 0 - 9, to images of hand-written digits. We'll use a preprocessed subset of the well-known [MNIST database of handwritten digits](https://en.wikipedia.org/wiki/MNIST_database). Take a moment now to familiarize yourself with the subject matter of this data set, and take a look at the properties of [the UCI ML hand-written digits dataset](https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits).\n",
    "\n",
    "## What to Do\n",
    "\n",
    "We'll guide you one step at a time in this walkthrough of a k-NN workflow. Try out the code, answer the Knowledge Check questions along the way, and engage in a few challenges to exercise your understanding and have some fun.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "We would like to \"transform\" sequences of handwritten digits into real numeric values that a computer can understand. For example, we would like a machine to be able to \"read\" a handwritten **8675309** and interpret each digit, resulting in the numeric string `8675309`. As such, we would like to construct a classifier that, as accurately as possible, can identify a visual representation of integers (pictures of handwritten numbers), and classify each image with one of ten labels: 0, 1, 2, 3, 4, 5, 6, 7, 8 or 9.\n",
    "\n",
    "## Obtaining the data\n",
    "\n",
    "For this experiment, we will get up and running quickly with [a subset of the MNIST data, bundled in the scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) library. First, let's import a typical toolkit of libraries, including pandas, matplotlib, and [scikit-learn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "```\n",
    "\n",
    "Here we are importing two essential libraries, and giving them aliases `pd`, `plt`, and importing the `load_digits` function, which will give use our data set.\n",
    "\n",
    "Let's load the data into memory as well, assigning it to a variable.\n",
    "\n",
    "```python\n",
    "digits = load_digits(as_frame=True)\n",
    "```\n",
    "\n",
    "Note that `load_digits` returns a [Bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch) object - not a pandas DataFrame. Review the [load_digits documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits) to see what the attributes of our particular Bunch are. We pass `load_digits` the named argument `as_frame=True` up front now, so that we can access the data as a DataFrame later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a00e354e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:21.914019Z",
     "iopub.status.busy": "2023-04-21T05:52:21.913585Z",
     "iopub.status.idle": "2023-04-21T05:52:23.215742Z",
     "shell.execute_reply": "2023-04-21T05:52:23.214767Z"
    },
    "papermill": {
     "duration": 1.318268,
     "end_time": "2023-04-21T05:52:23.218627",
     "exception": false,
     "start_time": "2023-04-21T05:52:21.900359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5030c954",
   "metadata": {
    "papermill": {
     "duration": 0.011809,
     "end_time": "2023-04-21T05:52:23.242661",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.230852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Let's investigate the description, shape, feature names, and target label names of the `data` set stored in the Bunch. We know about these attributes from the documentation of [`load_digits`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits). Try inspecting each of these properties one at a time.\n",
    "\n",
    "```python\n",
    "print(digits.DESCR)\n",
    "digits.data.shape\n",
    "digits.feature_names\n",
    "digits.target_names\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6edcbc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:23.268360Z",
     "iopub.status.busy": "2023-04-21T05:52:23.267956Z",
     "iopub.status.idle": "2023-04-21T05:52:23.275507Z",
     "shell.execute_reply": "2023-04-21T05:52:23.274602Z"
    },
    "papermill": {
     "duration": 0.02309,
     "end_time": "2023-04-21T05:52:23.277727",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.254637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(digits.DESCR)\n",
    "#digits.data.shape\n",
    "#digits.feature_names\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a044ff",
   "metadata": {
    "papermill": {
     "duration": 0.011653,
     "end_time": "2023-04-21T05:52:23.301342",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.289689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Knowledge Check 1\n",
    "\n",
    "1. How many individual handwritten characters are represented in the data set?\n",
    "\n",
    "1797 individual characters.\n",
    "\n",
    "2. How many dimensions are there, not counting the class label?\n",
    "\n",
    "64 dimensions\n",
    "\n",
    "3. What do the dimensions of each record represent? (What does one row of data have to do with a handwritten digit?)\n",
    "\n",
    "Each dimension represents a different pixel. Each datapoint is an 8x8 image of a number, so there are 64 total pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd63cd8f",
   "metadata": {
    "papermill": {
     "duration": 0.011636,
     "end_time": "2023-04-21T05:52:23.325154",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.313518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Exploring the DataFrame\n",
    "\n",
    "Now, let's access the data as a pandas DataFrame, for convenience and some quick summary stats.\n",
    "\n",
    "```python\n",
    "frame = digits.frame\n",
    "frame\n",
    "```\n",
    "\n",
    "Here we are obtaining the DataFrame, and inspecting it within the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1534aa25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:23.351883Z",
     "iopub.status.busy": "2023-04-21T05:52:23.351119Z",
     "iopub.status.idle": "2023-04-21T05:52:23.404093Z",
     "shell.execute_reply": "2023-04-21T05:52:23.402741Z"
    },
    "papermill": {
     "duration": 0.069555,
     "end_time": "2023-04-21T05:52:23.406849",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.337294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  target  \n",
       "0           0.0       0  \n",
       "1           0.0       1  \n",
       "2           0.0       2  \n",
       "3           0.0       3  \n",
       "4           0.0       4  \n",
       "...         ...     ...  \n",
       "1792        0.0       9  \n",
       "1793        0.0       0  \n",
       "1794        0.0       8  \n",
       "1795        0.0       9  \n",
       "1796        0.0       8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = digits.frame\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a32b99",
   "metadata": {
    "papermill": {
     "duration": 0.012211,
     "end_time": "2023-04-21T05:52:23.431812",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.419601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's investigate some summary statistics with `describe`.\n",
    "\n",
    "```python\n",
    "frame.describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f480415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:23.459350Z",
     "iopub.status.busy": "2023-04-21T05:52:23.458246Z",
     "iopub.status.idle": "2023-04-21T05:52:23.635274Z",
     "shell.execute_reply": "2023-04-21T05:52:23.633980Z"
    },
    "papermill": {
     "duration": 0.193428,
     "end_time": "2023-04-21T05:52:23.637758",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.444330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303840</td>\n",
       "      <td>5.204786</td>\n",
       "      <td>11.835838</td>\n",
       "      <td>11.848080</td>\n",
       "      <td>5.781859</td>\n",
       "      <td>1.362270</td>\n",
       "      <td>0.129661</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>1.993879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206455</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>5.557596</td>\n",
       "      <td>12.089037</td>\n",
       "      <td>11.809126</td>\n",
       "      <td>6.764051</td>\n",
       "      <td>2.067891</td>\n",
       "      <td>0.364496</td>\n",
       "      <td>4.490818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907192</td>\n",
       "      <td>4.754826</td>\n",
       "      <td>4.248842</td>\n",
       "      <td>4.287388</td>\n",
       "      <td>5.666418</td>\n",
       "      <td>3.325775</td>\n",
       "      <td>1.037383</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>3.196160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.934302</td>\n",
       "      <td>5.103019</td>\n",
       "      <td>4.374694</td>\n",
       "      <td>4.933947</td>\n",
       "      <td>5.900623</td>\n",
       "      <td>4.090548</td>\n",
       "      <td>1.860122</td>\n",
       "      <td>2.865304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel_0_0    pixel_0_1    pixel_0_2    pixel_0_3    pixel_0_4  \\\n",
       "count     1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean         0.0     0.303840     5.204786    11.835838    11.848080   \n",
       "std          0.0     0.907192     4.754826     4.248842     4.287388   \n",
       "min          0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "25%          0.0     0.000000     1.000000    10.000000    10.000000   \n",
       "50%          0.0     0.000000     4.000000    13.000000    13.000000   \n",
       "75%          0.0     0.000000     9.000000    15.000000    15.000000   \n",
       "max          0.0     8.000000    16.000000    16.000000    16.000000   \n",
       "\n",
       "         pixel_0_5    pixel_0_6    pixel_0_7    pixel_1_0    pixel_1_1  ...  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
       "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
       "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
       "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
       "\n",
       "         pixel_6_7    pixel_7_0    pixel_7_1    pixel_7_2    pixel_7_3  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      0.206455     0.000556     0.279354     5.557596    12.089037   \n",
       "std       0.984401     0.023590     0.934302     5.103019     4.374694   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     1.000000    11.000000   \n",
       "50%       0.000000     0.000000     0.000000     4.000000    13.000000   \n",
       "75%       0.000000     0.000000     0.000000    10.000000    16.000000   \n",
       "max      13.000000     1.000000     9.000000    16.000000    16.000000   \n",
       "\n",
       "         pixel_7_4    pixel_7_5    pixel_7_6    pixel_7_7       target  \n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
       "mean     11.809126     6.764051     2.067891     0.364496     4.490818  \n",
       "std       4.933947     5.900623     4.090548     1.860122     2.865304  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%      10.000000     0.000000     0.000000     0.000000     2.000000  \n",
       "50%      14.000000     6.000000     0.000000     0.000000     4.000000  \n",
       "75%      16.000000    12.000000     2.000000     0.000000     7.000000  \n",
       "max      16.000000    16.000000    16.000000    16.000000     9.000000  \n",
       "\n",
       "[8 rows x 65 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00807e6f",
   "metadata": {
    "papermill": {
     "duration": 0.012615,
     "end_time": "2023-04-21T05:52:23.663501",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.650886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We know from `DESCR` that the pixel values range from 0 to 16, and our quick survey of `describe` seems to confirm this, so we'll move forward with our assumptions about the data set. (In addition, `DESCR` promises us that there are no missing values - the preprocessing work has been done.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b5521",
   "metadata": {
    "papermill": {
     "duration": 0.012662,
     "end_time": "2023-04-21T05:52:23.689010",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.676348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Knowledge Check 2\n",
    "\n",
    "Based on the summary statistics, what is interesting about attribute *pixel_0_0*, and what do those interesting qualities lead you to conclude? Please describe it in very approachable terms, regarding the handwritten images, that anyone can understand.\n",
    "\n",
    "The pixel_0_0 is interesting because the value is always 0. My best guess is that the pixel was intentionally left blank as a control measure for when the programs by NIST extracted the values from the handwritten forms. If there were values in that pixel, the reseachers would know something was wrong with the extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331171d7",
   "metadata": {
    "papermill": {
     "duration": 0.012711,
     "end_time": "2023-04-21T05:52:23.714731",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.702020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualize the Data\n",
    "\n",
    "Let's take a visual look at one of the images. The `digits` Bunch has a property, `images`, that is an array of all of the raw image data. Let's access one image and visualize it on the screen.\n",
    "\n",
    "```python\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb33580c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:23.742740Z",
     "iopub.status.busy": "2023-04-21T05:52:23.742308Z",
     "iopub.status.idle": "2023-04-21T05:52:24.102733Z",
     "shell.execute_reply": "2023-04-21T05:52:24.101753Z"
    },
    "papermill": {
     "duration": 0.377577,
     "end_time": "2023-04-21T05:52:24.105361",
     "exception": false,
     "start_time": "2023-04-21T05:52:23.727784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0eabda",
   "metadata": {
    "papermill": {
     "duration": 0.013177,
     "end_time": "2023-04-21T05:52:24.132235",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.119058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Knowledge Check 3\n",
    "\n",
    "1. The figure is drawn at a scale of 640x480 pixels, but how many pixels wide and tall are the actual character images?\n",
    "\n",
    "The actual character images are 8x8 pixels.\n",
    "\n",
    "2. What does this have to do with the dimensions of the data set?\n",
    "\n",
    "This is why there are 64 features (or 64 dimensions), because 8x8=64. There are a total of 64 pixels, and each pixel has a number assigned to it from 0 to 16. These 64 numbers are the features for each character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c4b46",
   "metadata": {
    "papermill": {
     "duration": 0.012986,
     "end_time": "2023-04-21T05:52:24.158648",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.145662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the Training and Validation Sets\n",
    "\n",
    "With preprocessing gratefully handled for us, we now turn to creating our training set and validation sets. While we could manually implement our own sampling technique, this time we will lean on the `sklearn.model_selection.train_test_split` method. Be sure to check out the documentation for [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=0)\n",
    "```\n",
    "\n",
    "Notice how we pass `train_test_split` two arrays: one array, `digits.data`, containing all of the attributes except the class label dimension, and a second array, `digits.target`, containing the class labels for each record in the data set. We also specify that we'd like to use 80% of the records for training, and 20% of the records for testing. (Here we are also assigning `0` to `random_state`, and this is only for the sake of this exercise, to control the random seed so that running our notebook repeatedly gives us the same, albeit randomized, sampling.)\n",
    "\n",
    "The function `train_test_split` returns four arrays, conveniently splitting our complete data set into randomized training and validation sets:\n",
    "\n",
    "- `X_train`: our training records, without the class labels\n",
    "- `y_train`: the class labels for our training records\n",
    "- `X_test`: our validation records, without the class labels\n",
    "- `y_test`: the class labels for our validation records\n",
    "\n",
    "This is a very common naming convention we see in practice, so we'll abide by it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75c82e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.187805Z",
     "iopub.status.busy": "2023-04-21T05:52:24.187295Z",
     "iopub.status.idle": "2023-04-21T05:52:24.260487Z",
     "shell.execute_reply": "2023-04-21T05:52:24.259078Z"
    },
    "papermill": {
     "duration": 0.091286,
     "end_time": "2023-04-21T05:52:24.263485",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.172199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480031f",
   "metadata": {
    "papermill": {
     "duration": 0.01318,
     "end_time": "2023-04-21T05:52:24.290347",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.277167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Instantiate and \"Train\" our Classifier\n",
    "\n",
    "We'll next instantiate a k-NN classifier provided by scikit-learn: the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Please be sure to read the documentation, noticing both the parameters we can pass the KNeighborsClassifier initializer, such as the distance metric to use, and in particular, `n_neighbors` which is our **_k_**.\n",
    "\n",
    "We'll rely on some defaults, but start with a fairly unsurprising **_k_**, the square root of the number of records in the training set.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = int(sqrt(len(X_train))))\n",
    "```\n",
    "\n",
    "Import the KNeighborsClassifier and instantiate it the next code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "509ca5c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.319719Z",
     "iopub.status.busy": "2023-04-21T05:52:24.319224Z",
     "iopub.status.idle": "2023-04-21T05:52:24.514024Z",
     "shell.execute_reply": "2023-04-21T05:52:24.512919Z"
    },
    "papermill": {
     "duration": 0.212794,
     "end_time": "2023-04-21T05:52:24.516906",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.304112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = int(sqrt(len(X_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd573f3",
   "metadata": {
    "papermill": {
     "duration": 0.013115,
     "end_time": "2023-04-21T05:52:24.543503",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.530388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we have to \"train our model,\" but, as we know, k-NN classifiers are instance-based learners with no initial training computation. All we need to do is provide the classifier with the training data.\n",
    "\n",
    "```python\n",
    "classifier.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Here we invoke the commonplace `fit` method found in tha API of many pre-built classification models. Here, we simply pass it our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01edc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.572959Z",
     "iopub.status.busy": "2023-04-21T05:52:24.571982Z",
     "iopub.status.idle": "2023-04-21T05:52:24.589198Z",
     "shell.execute_reply": "2023-04-21T05:52:24.587882Z"
    },
    "papermill": {
     "duration": 0.034449,
     "end_time": "2023-04-21T05:52:24.591600",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.557151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=37)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e68dd",
   "metadata": {
    "papermill": {
     "duration": 0.013826,
     "end_time": "2023-04-21T05:52:24.619006",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.605180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Knowledge Check 4\n",
    "\n",
    "Using the documentation, investigate the other \"nearest neighbor\" classifiers in the scikit-learn library, in the `sklearn.neighbors` namespace. Identify (name) two other classifiers, and briefly describe how they are different from KNeighborsClassifier. Don't just regurgitate the documentation - do a little online sleuthing to see how they are useful, and share that information here.\n",
    "\n",
    "The`RadiusNeighborsClassifier` is different than the `KNeighborsClassifier` because instead of considering a fixed number of neighbors k, it considers all neighbors within a fixed radius. This classifier is useful when there is a non-uniform distribution of samples, so a fixed number of neighbors is not ideal for differentiating between every class.\n",
    "\n",
    "`NearestCentroid` is different than the `KNeighborsClassifier` because instead of looking at individual neighbors, it calculates the centroid of the training samples for each class. Then the predictions are made based on the closest centroid point. This would work well where classes are well-separated, but would not be ideal for overlapping or noisy data sets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5964e996",
   "metadata": {
    "papermill": {
     "duration": 0.01304,
     "end_time": "2023-04-21T05:52:24.645973",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.632933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validate (Test) Our Classifier\n",
    "\n",
    "The next step in our ML process is to see how well our classifier performs, given our training set and, in this case, our initial **_k_**. We'll ask the classifier to predict the class label for every record in our validation set, `X_test`. Then, we'll compare those predictions with the actual class labels, in `y_test`, and compute an accuracy score. Rather than do this manually, we'll rely on the scikit-learn [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) function. Be sure to read the documentation for `accuracy_score`.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predictions)\n",
    "```\n",
    "\n",
    "Here we invoke the KNeighborsClassifier `predict` method, which returns an array of predicted class labels for each record in `X_test`, that we assign to `y_predictions`. We then pass `accuracy_score` the known correct class labels for the validation set, `y_test`, and the predicted labels, `y_predictions`, and let it make the comparisons, tally up the correct matches, and compute and return an accuracy score between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b00420e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.674746Z",
     "iopub.status.busy": "2023-04-21T05:52:24.674281Z",
     "iopub.status.idle": "2023-04-21T05:52:24.737059Z",
     "shell.execute_reply": "2023-04-21T05:52:24.735208Z"
    },
    "papermill": {
     "duration": 0.082693,
     "end_time": "2023-04-21T05:52:24.742139",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.659446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae553bd1",
   "metadata": {
    "papermill": {
     "duration": 0.031946,
     "end_time": "2023-04-21T05:52:24.809113",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.777167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's inspect that accuracy score by simply printing it.\n",
    "\n",
    "```python\n",
    "print(accuracy)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7518504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.837606Z",
     "iopub.status.busy": "2023-04-21T05:52:24.837154Z",
     "iopub.status.idle": "2023-04-21T05:52:24.843518Z",
     "shell.execute_reply": "2023-04-21T05:52:24.842183Z"
    },
    "papermill": {
     "duration": 0.023958,
     "end_time": "2023-04-21T05:52:24.846351",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.822393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a6fc6",
   "metadata": {
    "papermill": {
     "duration": 0.013272,
     "end_time": "2023-04-21T05:52:24.873330",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.860058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hm - not bad!\n",
    "\n",
    "There's one more way we can analyze the performance of our classifier: by inspecting a matrix of expected vs predicted class labels, known as a *confusion matrix*. For each cell in the matrix, we'll see the number of predictions, whether right or wrong, made for each of the known class labels.\n",
    "\n",
    "We'll reach for the scikit-learn [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to generate a confusion matrix for us.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predictions)\n",
    "```\n",
    "\n",
    "We import the `confusion_matrix` function, and then invoke it, passing it the expected class labels in the validation set, `y_test`, and the predicted labels, `y_predictions`. It returns, in essence, a matrix, which we assign to `confusion_matrix`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f268507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.902638Z",
     "iopub.status.busy": "2023-04-21T05:52:24.901786Z",
     "iopub.status.idle": "2023-04-21T05:52:24.909471Z",
     "shell.execute_reply": "2023-04-21T05:52:24.908614Z"
    },
    "papermill": {
     "duration": 0.025223,
     "end_time": "2023-04-21T05:52:24.911987",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.886764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da1e8f",
   "metadata": {
    "papermill": {
     "duration": 0.013195,
     "end_time": "2023-04-21T05:52:24.938632",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.925437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, let's inspect the confusion matrix by simply printing it.\n",
    "\n",
    "```python\n",
    "print(confusion_matrix)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8436c935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:24.968465Z",
     "iopub.status.busy": "2023-04-21T05:52:24.967614Z",
     "iopub.status.idle": "2023-04-21T05:52:24.974711Z",
     "shell.execute_reply": "2023-04-21T05:52:24.973328Z"
    },
    "papermill": {
     "duration": 0.024383,
     "end_time": "2023-04-21T05:52:24.977111",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.952728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  0  0  0  0  0  0  0  0]\n",
      " [ 1  0 32  1  0  0  0  1  1  0]\n",
      " [ 0  0  0 29  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  3  0  1  0  0  1  1 33  0]\n",
      " [ 0  0  0  0  0  1  0  1  0 39]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51efc811",
   "metadata": {
    "papermill": {
     "duration": 0.013755,
     "end_time": "2023-04-21T05:52:25.004684",
     "exception": false,
     "start_time": "2023-04-21T05:52:24.990929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The horizontal axis of a confusion matrix represents the predicted labels, and the vertical axis represents the correct class labels. Each entry in the matrix represents the number of images predicted to have that class label.\n",
    "\n",
    "Notice how well this classifer performed, with our default **_k_**, euclidean distance, and a (luckily!) high-quality data set. We can see the 27 of the **0** handwritten images are correctly classified, and none are misclassified. If we look at the last row in the confusion matrix, we see that 39 of the **9** images are correctly classified, but one was classified as a **5**, and another classified as a **7**.\n",
    "\n",
    "### But, can you do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf663ef",
   "metadata": {
    "papermill": {
     "duration": 0.013269,
     "end_time": "2023-04-21T05:52:25.031671",
     "exception": false,
     "start_time": "2023-04-21T05:52:25.018402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Knowledge Check 5\n",
    "\n",
    "Inspect the confusion matrix. Which handwritten letter seemed to be the \"hardest\" for our classifier to predict correctly? What evidence in the confusion matrix leads you to assert this?\n",
    "\n",
    "8 seemed to be the hardest for the classifier to predict correctly. I say this because it had the most errors. 3 times an 8 was predicted as a 1, once as a 3, once as a 6, and once as a 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a53fda",
   "metadata": {
    "papermill": {
     "duration": 0.013385,
     "end_time": "2023-04-21T05:52:25.059107",
     "exception": false,
     "start_time": "2023-04-21T05:52:25.045722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tune the Classifier: Find the Best **_k_**\n",
    "\n",
    "Now it's your turn. Given what we have seen in the course thus far, and the `sklearn` API seen in this notebook, create an iterative experiment that inspects the accuracy of different classifiers using different **_k_** values. Your goal is to configure a classifier that exhibits the highest possible accuracy. Start your experiment with the traditional initial **_k_**, the square root of the number of records in the training set.\n",
    "\n",
    "Your experiment should demonstrate:\n",
    "\n",
    "- Creating KNeighborsClassifiers with different **_k_** values\n",
    "- \"Training\" and validating the classifiers\n",
    "- Capturing and presenting the accuracy for each **_k_**\n",
    "\n",
    "Keep your experiment simple. (Hint: Use a loop.)\n",
    "\n",
    "Conclude your experiment with a markdown cell that asserts your proposed **_k_**, the accuracy of your classifier, and what leads you to choose this value of **_k_**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0844d158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:25.088790Z",
     "iopub.status.busy": "2023-04-21T05:52:25.087900Z",
     "iopub.status.idle": "2023-04-21T05:52:42.855623Z",
     "shell.execute_reply": "2023-04-21T05:52:42.854645Z"
    },
    "papermill": {
     "duration": 17.785586,
     "end_time": "2023-04-21T05:52:42.858184",
     "exception": false,
     "start_time": "2023-04-21T05:52:25.072598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 💡 Knowledge Check 6 Code\n",
    "\n",
    "# Dictionary to store accuracy values\n",
    "accuracy_dict = {}\n",
    "\n",
    "# Initial k is 37\n",
    "for k_value in range(1,250):\n",
    "    classifier = KNeighborsClassifier(n_neighbors = k_value)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_predictions = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_predictions)\n",
    "    accuracy_dict[k_value] = accuracy\n",
    "\n",
    "x = accuracy_dict.keys()\n",
    "y = accuracy_dict.values()\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dff246b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T05:52:42.888808Z",
     "iopub.status.busy": "2023-04-21T05:52:42.888364Z",
     "iopub.status.idle": "2023-04-21T05:52:42.894508Z",
     "shell.execute_reply": "2023-04-21T05:52:42.893188Z"
    },
    "papermill": {
     "duration": 0.025468,
     "end_time": "2023-04-21T05:52:42.897749",
     "exception": false,
     "start_time": "2023-04-21T05:52:42.872281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.9888888888888889, 2: 0.9805555555555555, 3: 0.9833333333333333, 4: 0.975, 5: 0.975}\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "first_n_items = dict(islice(accuracy_dict.items(), 5))\n",
    "print(first_n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77a61b",
   "metadata": {
    "papermill": {
     "duration": 0.013832,
     "end_time": "2023-04-21T05:52:42.925901",
     "exception": false,
     "start_time": "2023-04-21T05:52:42.912069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 💡 Knowledge Check 6\n",
    "\n",
    "Conclude your experiment with a brief assertion of your proposed **_k_**, the accuracy of your classifier, and what led you to choose this value of **_k_**.\n",
    "\n",
    "I would propose a k value of 3. The accuracy my of classifier is 98.3%. I chose this value of k because it gave me a very high accuracy. The only k value with a higher accuracy was a k value of 1, which gave me 98.9% accuracy. While this is technically better, having only 1 neighbor involved in the decision would make it very sensitive to noise and outliers in the data. I am also worried it may be overfitting the data. I picked 3 to make the model a bit more stable and still maintain the high accuracy. The plot above shows the trend that the accuracy decreased the more I increased the k value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163afd97",
   "metadata": {
    "papermill": {
     "duration": 0.013728,
     "end_time": "2023-04-21T05:52:42.953972",
     "exception": false,
     "start_time": "2023-04-21T05:52:42.940244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Congratulations on finishing an authentic machine learning workflow! While our dataset is of high quality, and the drama of preprocessing is abbreviated, we hope that this notebook enables you to see how we can use ML tools to carry out much of the machine learning process.\n",
    "\n",
    "Please wrap up this notebook with a brief narrative.\n",
    "\n",
    "### 💡 Knowledge Check 7\n",
    "\n",
    "Imagine that a \"person on the street\" (or your twelve-year-old relative) asks you, \"What does it take for a computer to recognize handwritten characters that get scanned and turned into computable numbers?\" Rely on our journey through this notebook, infer and deduce what you can as necessary, but be mindful of your audience: please explain things in a manner befitting someone who knows nothing about these things.\n",
    "\n",
    "Conclude with your assertion about whether or not character recognition is an \"easy\" or \"very difficult\" machine learning problem, and whether or not this surprises you.\n",
    "\n",
    "The first step for computers to be able to recognize handwritten characters is turning an image of a character into numbers that can represent it. The character needs to be bound by a box, and then that box needs to be separated into a grid of more boxes, also called pixels. The pixel is the smallest unit of a picture, and can be represented as a number, which represents the color that it shows. In the case of characters, each number would represent the intensity of color, say 0 for white (blank) and 1 for completely black. If it was gray, the number could be 0.5. Then, each image, consisting of these pixels, could be represented by a row of numbers. Each number in the row would represent how dark the pixel is. This is how computers store pictures in memory.\n",
    "\n",
    "Now that we have characters stored as rows of numbers (like in a picture), we can start collecting lots of pictures of characters and grouping them together. Many people writing '3' would likely fill in the same pixels with ink over and over, which would show as a distinct pattern in the row of numbers. With a lot of data collected and labeled with the correct character they represent, the computer can compare new characters with the patterns in the row of numbers it has in memory. It can then group the new character image with a known group of character images, thereby recognizing handwritten characters.\n",
    "\n",
    "I think character recognition is an easy machine learning problem. We know what is different about each character and know how to feed that information into a computer. This does not surprise me.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.663784,
   "end_time": "2023-04-21T05:52:43.792829",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-21T05:52:09.129045",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
