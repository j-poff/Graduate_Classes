{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084f84ee",
   "metadata": {
    "papermill": {
     "duration": 0.012623,
     "end_time": "2023-05-19T23:01:24.518911",
     "exception": false,
     "start_time": "2023-05-19T23:01:24.506288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains two parts. **Part 1, Logistic Regression**, provides you an opportunity to demonstrate your ability to apply course concepts by implementing a training function for logistic regression. **Part 2, Classifying Fashion Items**, provides you an opportunity to practice using widely-used ML libraries and an ML workflow to analyze a classification problem using a logistic regression model.\n",
    "\n",
    "**You do not need to complete Part 1 in order to complete Part 2**. If you get stuck on Part 1, and choose to work on Part 2, be sure that all of your code for Part 1 runs without error. You can comment out your code in Part 1 if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce6bc0",
   "metadata": {
    "papermill": {
     "duration": 0.01131,
     "end_time": "2023-05-19T23:01:24.542234",
     "exception": false,
     "start_time": "2023-05-19T23:01:24.530924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 1: Implementing Logistic Regression\n",
    "\n",
    "Given a nearly-complete LogisticRegressor, and a simple training set of tumor data, demonstrate your ability to implement a logistic regression model's `fit` function, such that it properly trains its model using gradient descent.\n",
    "\n",
    "## The LogisticRegressor\n",
    "\n",
    "Let's first review the LogisticRegressor, which you should find familiar. Notice that the `fit` method uses a fixed number of iterations, only for simplicity and experimentation, and is stubbed to do nothing. But, also notice that the comments in `fit` describe a training process using gradient descent.\n",
    "\n",
    "Run the code cell and observe the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e69a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:24.568236Z",
     "iopub.status.busy": "2023-05-19T23:01:24.567756Z",
     "iopub.status.idle": "2023-05-19T23:01:28.730304Z",
     "shell.execute_reply": "2023-05-19T23:01:28.728994Z"
    },
    "papermill": {
     "duration": 4.180184,
     "end_time": "2023-05-19T23:01:28.734180",
     "exception": false,
     "start_time": "2023-05-19T23:01:24.553996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for [0.5, 1.5] is 0\n",
      "Prediction for [1, 1] is 0\n",
      "Prediction for [1.5, 0.5] is 0\n",
      "Prediction for [3, 0.5] is 1\n",
      "Prediction for [2, 2] is 1\n",
      "Prediction for [1, 2.5] is 1\n",
      "0.0016974661879524142\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class LogisticRegressor:\n",
    "\n",
    "    def __init__(self, w = 0, b = 0, alpha = 0.1):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "    # Get number of features from the first data object\n",
    "        feature_count = len(x_train[0])\n",
    "        for _ in range(0, 100000):\n",
    "            # Determine the changes that need to be made to w\n",
    "            delta_w = self._d_cost_function_w(x_train, y_train)\n",
    "            # Determine the changes that need to be made to b\n",
    "            delta_b = self._d_cost_function_b(x_train, y_train)\n",
    "            # For each weight element in the w vector\n",
    "            for feature_index in range(feature_count):\n",
    "                # Update the weight (subtract the change times alpha)\n",
    "                self.w[feature_index] = self.w[feature_index] - self.alpha * delta_w[feature_index]\n",
    "            # Update the bias (subtract the change times alpha)\n",
    "            self.b = self.b - self.alpha * delta_b                \n",
    "\n",
    "    def cost(self, x_examples, y_class_labels):\n",
    "        cost = 0\n",
    "        for i in range(len(x_examples)):\n",
    "            cost += self._loss(x_examples[i], y_class_labels[i])\n",
    "        return cost / len(x_examples)\n",
    "\n",
    "    def _loss(self, x, y):\n",
    "        z = self._dot_product(self.w, x) + self.b\n",
    "        return -y * math.log(self._sigmoid(z)) - (1 - y) * math.log(1- self._sigmoid(z))\n",
    "\n",
    "    def _d_cost_function_w(self, x_train, y_train):\n",
    "        delta_w = [0] * len(x_train[0])\n",
    "        for i in range(len(x_train)):\n",
    "            error = self._sigmoid(self._dot_product(self.w, x_train[i]) + self.b) - y_train[i]\n",
    "            for j in range(len(delta_w)):\n",
    "                delta_w[j] += error * x_train[i][j]\n",
    "        for i in range(len(delta_w)):\n",
    "            delta_w[i] = delta_w[i] / len(x_train)\n",
    "        return delta_w\n",
    "\n",
    "    def _d_cost_function_b(self, x_train, y_train):\n",
    "        delta_b = 0\n",
    "        for i in range(len(x_train)):\n",
    "            delta_b += self._sigmoid(self._dot_product(self.w, x_train[i]) + self.b) - y_train[i]\n",
    "        return delta_b / len(x_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self._sigmoid( self._dot_product(self.w, x) + self.b) >= 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _dot_product(self, a, b):\n",
    "        return sum(pair[0] * pair[1] for pair in zip(a, b))\n",
    "\n",
    "    def _sigmoid(self, exponent):\n",
    "        return 1 / (1 + math.exp(-exponent))\n",
    "\n",
    "\n",
    "\n",
    "x_train = [[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]]\n",
    "y_train = [0, 0, 0, 1, 1, 1]\n",
    "\n",
    "regressor = LogisticRegressor([0, 0], 0, 0.1)\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "for example in x_train:\n",
    "    print(f\"Prediction for {example} is {regressor.predict(example)}\")\n",
    "\n",
    "print(regressor.cost(x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49eefcc",
   "metadata": {
    "papermill": {
     "duration": 0.011528,
     "end_time": "2023-05-19T23:01:28.758617",
     "exception": false,
     "start_time": "2023-05-19T23:01:28.747089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see from the output, our classifier is currently predicting only a 1, and its cost is about 0.69.\n",
    "\n",
    "## What to Do\n",
    "\n",
    "Your goal is to implement, in the code cell above, the `fit` function. When complete, you should see results identical to the output shown at the end of the *Exploration: Applying Logistic Regression*.\n",
    "\n",
    "1. Implement the `fit` function in the code cell above.\n",
    "2. Run the code cell frequently, and observe the output.\n",
    "3. When you believe your implementation is complete, increase the number of iterations. Compare your output to what we have seen in the corresponding Exploration.\n",
    "4. Rely on the functions that are already implemented for you, such as `_d_cost_function_b` and `_d_cost_function_w`.\n",
    "\n",
    "The best tip for thinking about this challenge is to become intimately familiar with the process of gradient descent, and recognizing what `_d_cost_function_b` and `_d_cost_function_w` return. **Use the comments in the `fit` function as a general guide, not a literal line-by-line translation into code.**\n",
    "\n",
    "You'll know your implementation is sound when the output of the code cell matches what we have seen in the *Exploration: Applying Logistic Regression*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d77a82",
   "metadata": {
    "papermill": {
     "duration": 0.011766,
     "end_time": "2023-05-19T23:01:28.782624",
     "exception": false,
     "start_time": "2023-05-19T23:01:28.770858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ’¡ Conclusion\n",
    "\n",
    "I first started by looking back at my notebook for linear regression. After familiarizing myself with the general flow, I examined the cost functions to see what the outputs were and to check and make sure they included the changes needed for a logistic regression. I was happy to see the cost function already looped through the weights and provided a list. After that, it was easy to follow the pseudocode and simply invoke the existing functions. The only slight change I made from the process in the linear regression code was waiting to multiply by the alpha until the line that updated the weights and bias. I only realized I needed to do this when I ran the code and experienced an error. I changed the number of steps as shown in the exploration and got the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1ad1e3",
   "metadata": {
    "papermill": {
     "duration": 0.011633,
     "end_time": "2023-05-19T23:01:28.806620",
     "exception": false,
     "start_time": "2023-05-19T23:01:28.794987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Part 2: Classifying Fashion Items\n",
    "\n",
    "In this, the second, part of this notebook, you will observe a non-annotated implementation of a machine learning process, and enhance it with descriptive markdown cells and additional code. Your goal is to narrate and improve an experiment that measures the performance of the [scikit-learn LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model for classifying images of fashion items. We'll use the popular [Fashion MNIST data set](https://github.com/zalandoresearch/fashion-mnist) by Xiao, Rasul, and Vollgraf. Take a moment now to [familiarize yourself with the version of this data set](), and also take a look at [a version of this data on Kaggle](https://www.kaggle.com/datasets/zalando-research/fashionmnist).\n",
    "\n",
    "Unlike prior notebooks, in which you are given either a guided framework of steps, or provided explicit code to try, in this notebook the code shall be your framework. Your goal is to break apart this one big code cell into a cohesive, multi-section, narrated Notebook, that guides the reader through the machine learning process. You have seen and practiced this in prior Notebooks, and you are encouraged to replicate the spirit of our past work here.\n",
    "\n",
    "In other words, below you have a bunch of code. Your goal is to:\n",
    "\n",
    "1. Narrate a machine learning process\n",
    "2. Explain what the code is doing, and add to it as necessary\n",
    "3. Experiment, tune the model, and discuss your results\n",
    "\n",
    "Your Notebook should consist of many sections, with each section representing a step in the machine learning process. The first section, **Problem Statement**, has been completed for you. Each section should start with a markdown cell containing a descriptive second-level header, and at least a few sentences that prepare the reader for what the purpose of the step is.\n",
    "\n",
    "Each section should consist of both prose, in markdown cells, and code cells. Almost every section should consist of multiple markdown and code cells. You should often add to the provided code. For example, if you have a section on exploring data, you should probably do more than just look at the `head` and `shape`.\n",
    "\n",
    "Your first step is to run the code block, and spend time with each line of code to discern how it reflects some unit of work in our machine learning process.\n",
    "\n",
    "In the end, demonstrate how you modify the experiment and/or tune the model to increase the accuracy of the model. (Spend time with the [official documentation of the data set](https://github.com/zalandoresearch/fashion-mnist). What is the human accuracy score? Can your model surpass it when validated with the complete training set?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a22e87",
   "metadata": {
    "papermill": {
     "duration": 0.011516,
     "end_time": "2023-05-19T23:01:28.829876",
     "exception": false,
     "start_time": "2023-05-19T23:01:28.818360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Problem Statement\n",
    "\n",
    "Our goal is to automate the identification of images of ten different kinds of fashion items, from t-shirts to ankle boots. To do so, we will attempt to train a logistic regression model using a well-prepared data set of images of fashion items. Our goal is to tune our end-to-end machine learning process, and to tune our classification model, to see how accurately it may predict the correct class label of different fashion items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7a368",
   "metadata": {
    "papermill": {
     "duration": 0.011863,
     "end_time": "2023-05-19T23:01:28.853803",
     "exception": false,
     "start_time": "2023-05-19T23:01:28.841940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1: Exploring the data\n",
    "\n",
    "Our first step in any machine learning process is understanding our data. The data we will be using is the popular Fashion MNIST data set by Xiao, Rasul, and Vollgraf. The data comes from this website: https://www.kaggle.com/datasets/zalando-research/fashionmnist. \n",
    "\n",
    "If you follow the link, you will see it provides two different csv files. One is called \"fashion-mnist_test\" and the other is called \"fashion-mnist_train\". The metadata on the website says the training set has 60,000 examples and the testing set has 10,000 examples. Let's load both into the notebook and print the length of each to check. We will import and use the package pandas to load the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d017346",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:28.881556Z",
     "iopub.status.busy": "2023-05-19T23:01:28.881076Z",
     "iopub.status.idle": "2023-05-19T23:01:37.098949Z",
     "shell.execute_reply": "2023-05-19T23:01:37.097644Z"
    },
    "papermill": {
     "duration": 8.235062,
     "end_time": "2023-05-19T23:01:37.101362",
     "exception": false,
     "start_time": "2023-05-19T23:01:28.866300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data: 60000\n",
      "Length of testing data: 10000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fashion_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\n",
    "fashion_test_set = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\n",
    "print(\"Length of training data: \" + str(len(fashion_data)))\n",
    "print(\"Length of testing data: \" + str(len(fashion_test_set)))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25281aa3",
   "metadata": {
    "papermill": {
     "duration": 0.011626,
     "end_time": "2023-05-19T23:01:37.125409",
     "exception": false,
     "start_time": "2023-05-19T23:01:37.113783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This confirms what the website told us. Now let's figure out exactly what the data means. The kaggle website above gives us a very clear description of the data is. Let's read it:\n",
    "\n",
    "\"Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\"\n",
    "\n",
    "Now let's confirm what the website tells us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e22ae7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:37.152599Z",
     "iopub.status.busy": "2023-05-19T23:01:37.151846Z",
     "iopub.status.idle": "2023-05-19T23:01:37.158883Z",
     "shell.execute_reply": "2023-05-19T23:01:37.157420Z"
    },
    "papermill": {
     "duration": 0.023201,
     "end_time": "2023-05-19T23:01:37.161473",
     "exception": false,
     "start_time": "2023-05-19T23:01:37.138272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set: (60000, 785)\n",
      "Shape of the testing set: (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the training set: \" + str(fashion_data.shape))\n",
    "print(\"Shape of the testing set: \" + str(fashion_test_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9243510",
   "metadata": {
    "papermill": {
     "duration": 0.011721,
     "end_time": "2023-05-19T23:01:37.185422",
     "exception": false,
     "start_time": "2023-05-19T23:01:37.173701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are 785 columns in both datasets, which makes sense because each picture is 28x28 pixels, so that means there are 784 total. This leaves one column for the labels. Next let's use the pandas `.describe` method to make sure the values for each column are what we expect from our reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7638270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:37.211228Z",
     "iopub.status.busy": "2023-05-19T23:01:37.210813Z",
     "iopub.status.idle": "2023-05-19T23:01:40.584905Z",
     "shell.execute_reply": "2023-05-19T23:01:40.583718Z"
    },
    "papermill": {
     "duration": 3.390422,
     "end_time": "2023-05-19T23:01:40.587899",
     "exception": false,
     "start_time": "2023-05-19T23:01:37.197477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>0.247967</td>\n",
       "      <td>0.411467</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>2.198283</td>\n",
       "      <td>5.682000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.625400</td>\n",
       "      <td>23.300683</td>\n",
       "      <td>16.588267</td>\n",
       "      <td>17.869433</td>\n",
       "      <td>22.814817</td>\n",
       "      <td>17.911483</td>\n",
       "      <td>8.520633</td>\n",
       "      <td>2.753300</td>\n",
       "      <td>0.855517</td>\n",
       "      <td>0.07025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872305</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.271011</td>\n",
       "      <td>1.222324</td>\n",
       "      <td>2.452871</td>\n",
       "      <td>4.306912</td>\n",
       "      <td>5.836188</td>\n",
       "      <td>8.215169</td>\n",
       "      <td>14.093378</td>\n",
       "      <td>23.819481</td>\n",
       "      <td>...</td>\n",
       "      <td>57.545242</td>\n",
       "      <td>48.854427</td>\n",
       "      <td>41.979611</td>\n",
       "      <td>43.966032</td>\n",
       "      <td>51.830477</td>\n",
       "      <td>45.149388</td>\n",
       "      <td>29.614859</td>\n",
       "      <td>17.397652</td>\n",
       "      <td>9.356960</td>\n",
       "      <td>2.12587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       4.500000      0.000900      0.006150      0.035333      0.101933   \n",
       "std        2.872305      0.094689      0.271011      1.222324      2.452871   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     36.000000    226.000000    164.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.247967      0.411467      0.805767      2.198283      5.682000   \n",
       "std        4.306912      5.836188      8.215169     14.093378     23.819481   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    230.000000    224.000000    255.000000    254.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     34.625400     23.300683     16.588267     17.869433   \n",
       "std    ...     57.545242     48.854427     41.979611     43.966032   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     58.000000      9.000000      0.000000      0.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
       "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  60000.00000  \n",
       "mean       0.07025  \n",
       "std        2.12587  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      170.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682265cb",
   "metadata": {
    "papermill": {
     "duration": 0.012005,
     "end_time": "2023-05-19T23:01:40.612527",
     "exception": false,
     "start_time": "2023-05-19T23:01:40.600522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see that the 'label' column is indeed the first column, and that it ranges from 0 to 9. We also see all the columns for the pixels, with values ranging from 0 to 255 as expected. This all looks great. Let's check the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4571b38d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:40.639524Z",
     "iopub.status.busy": "2023-05-19T23:01:40.638878Z",
     "iopub.status.idle": "2023-05-19T23:01:42.664134Z",
     "shell.execute_reply": "2023-05-19T23:01:42.662914Z"
    },
    "papermill": {
     "duration": 2.041997,
     "end_time": "2023-05-19T23:01:42.666943",
     "exception": false,
     "start_time": "2023-05-19T23:01:40.624946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.826700</td>\n",
       "      <td>2.321200</td>\n",
       "      <td>5.457800</td>\n",
       "      <td>...</td>\n",
       "      <td>34.320800</td>\n",
       "      <td>23.071900</td>\n",
       "      <td>16.432000</td>\n",
       "      <td>17.870600</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>17.790200</td>\n",
       "      <td>8.353500</td>\n",
       "      <td>2.541600</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.06560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872425</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.525187</td>\n",
       "      <td>2.494315</td>\n",
       "      <td>2.208882</td>\n",
       "      <td>4.669183</td>\n",
       "      <td>5.657849</td>\n",
       "      <td>8.591731</td>\n",
       "      <td>15.031508</td>\n",
       "      <td>23.359019</td>\n",
       "      <td>...</td>\n",
       "      <td>57.888679</td>\n",
       "      <td>49.049749</td>\n",
       "      <td>42.159665</td>\n",
       "      <td>44.140552</td>\n",
       "      <td>51.706601</td>\n",
       "      <td>45.128107</td>\n",
       "      <td>28.765769</td>\n",
       "      <td>16.417363</td>\n",
       "      <td>7.462533</td>\n",
       "      <td>1.93403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>107.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       4.500000      0.000400      0.010300      0.052100      0.077000   \n",
       "std        2.872425      0.024493      0.525187      2.494315      2.208882   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000      2.000000     45.000000    218.000000    185.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.208600      0.349200      0.826700      2.321200      5.457800   \n",
       "std        4.669183      5.657849      8.591731     15.031508     23.359019   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    223.000000    247.000000    218.000000    244.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...     34.320800     23.071900     16.432000     17.870600   \n",
       "std    ...     57.888679     49.049749     42.159665     44.140552   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     55.000000      6.000000      0.000000      0.000000   \n",
       "max    ...    254.000000    252.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      22.860000     17.790200      8.353500      2.541600      0.629500   \n",
       "std       51.706601     45.128107     28.765769     16.417363      7.462533   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    240.000000    225.000000    205.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  10000.00000  \n",
       "mean       0.06560  \n",
       "std        1.93403  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      107.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_test_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386dab09",
   "metadata": {
    "papermill": {
     "duration": 0.012925,
     "end_time": "2023-05-19T23:01:42.693891",
     "exception": false,
     "start_time": "2023-05-19T23:01:42.680966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see the same things for the testing set as we saw for the training set.\n",
    "\n",
    "Let's make sure we understand the 'label' column. From the kaggle website that provides that data, it tells is that each integer from 0 to 9 represents a different type of clothing. The key is provided below: \n",
    "\n",
    "0 T-shirt/top,\n",
    "1 Trouser,\n",
    "2 Pullover,\n",
    "3 Dress,\n",
    "4 Coat,\n",
    "5 Sandal,\n",
    "6 Shirt,\n",
    "7 Sneaker,\n",
    "8 Bag,\n",
    "9 Ankle boot.\n",
    "\n",
    "It will be helpful later on to create a python dictionary mapping these numbers to the description. We will create that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45b78cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:42.722987Z",
     "iopub.status.busy": "2023-05-19T23:01:42.722205Z",
     "iopub.status.idle": "2023-05-19T23:01:42.728887Z",
     "shell.execute_reply": "2023-05-19T23:01:42.727769Z"
    },
    "papermill": {
     "duration": 0.02431,
     "end_time": "2023-05-19T23:01:42.731521",
     "exception": false,
     "start_time": "2023-05-19T23:01:42.707211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = {\n",
    "    0: 'T-shirt / Top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b963f",
   "metadata": {
    "papermill": {
     "duration": 0.012676,
     "end_time": "2023-05-19T23:01:42.757422",
     "exception": false,
     "start_time": "2023-05-19T23:01:42.744746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now have a solid understanding of the data we are using. The next step is getting the data ready for input into our machine learning algorithm.  \n",
    "\n",
    "## Step 2: Getting the data ready for training and testing\n",
    "\n",
    "Our first step is splitting the labels from the features. The labels are in the first column, and we can use that information to divide up the dataframe. The features will be stored in the variable \"X\", and all the labels will be stored in the variable \"Y\". Let's check using the `.head` method from pandas to make sure we split the data correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3786e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:42.785959Z",
     "iopub.status.busy": "2023-05-19T23:01:42.785508Z",
     "iopub.status.idle": "2023-05-19T23:01:42.923861Z",
     "shell.execute_reply": "2023-05-19T23:01:42.922715Z"
    },
    "papermill": {
     "duration": 0.15574,
     "end_time": "2023-05-19T23:01:42.926525",
     "exception": false,
     "start_time": "2023-05-19T23:01:42.770785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       5       0   \n",
       "3       0       0       0       1       2       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0        0  ...         0         0         0         0         0         0   \n",
       "1        0  ...         0         0         0         0         0         0   \n",
       "2        0  ...         0         0         0        30        43         0   \n",
       "3        0  ...         3         0         0         0         0         1   \n",
       "4        0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = fashion_data[fashion_data.columns[1:]]\n",
    "Y = fashion_data['label']\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83c0d9",
   "metadata": {
    "papermill": {
     "duration": 0.013071,
     "end_time": "2023-05-19T23:01:42.953136",
     "exception": false,
     "start_time": "2023-05-19T23:01:42.940065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This looks like what we want for the training features. The 'label' column is gone, and we have all the pixel columns from 1 to 784. Let's check the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ea5a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:42.982098Z",
     "iopub.status.busy": "2023-05-19T23:01:42.981695Z",
     "iopub.status.idle": "2023-05-19T23:01:42.989708Z",
     "shell.execute_reply": "2023-05-19T23:01:42.988433Z"
    },
    "papermill": {
     "duration": 0.02569,
     "end_time": "2023-05-19T23:01:42.992344",
     "exception": false,
     "start_time": "2023-05-19T23:01:42.966654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    9\n",
       "2    6\n",
       "3    0\n",
       "4    3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e78db84",
   "metadata": {
    "papermill": {
     "duration": 0.013395,
     "end_time": "2023-05-19T23:01:43.020157",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.006762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Although it's not formatted as a table, we see the first 5 values of the labels. They range from 0 to 9, which is what we expect. \n",
    "\n",
    "Now that we have the labels split from the features, let's visualize the image and the label for a few random data objects. To do this, let's define a function that prints the label for a data object then plots the image stored in the pixel values. Our dictionary comes in handy here. We need to import the matplotlib package to help with plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcbe9940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:43.049466Z",
     "iopub.status.busy": "2023-05-19T23:01:43.049080Z",
     "iopub.status.idle": "2023-05-19T23:01:43.054704Z",
     "shell.execute_reply": "2023-05-19T23:01:43.053585Z"
    },
    "papermill": {
     "duration": 0.02333,
     "end_time": "2023-05-19T23:01:43.057242",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.033912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_image(features, numeric_label):\n",
    "    print(f\"Class: {labels[numeric_label]}\")\n",
    "    plt.imshow(features.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d688a",
   "metadata": {
    "papermill": {
     "duration": 0.0133,
     "end_time": "2023-05-19T23:01:43.084463",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.071163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now with the function set up, let's use it to visualize some images. The next 3 code blocks will print the label and then plot the image below it for data objects with index 0, 10, and 59999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2f62e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:43.113982Z",
     "iopub.status.busy": "2023-05-19T23:01:43.113579Z",
     "iopub.status.idle": "2023-05-19T23:01:43.388658Z",
     "shell.execute_reply": "2023-05-19T23:01:43.387494Z"
    },
    "papermill": {
     "duration": 0.292887,
     "end_time": "2023-05-19T23:01:43.391054",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.098167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(X.loc[0].values, Y.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994aeab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:43.421613Z",
     "iopub.status.busy": "2023-05-19T23:01:43.420443Z",
     "iopub.status.idle": "2023-05-19T23:01:43.673885Z",
     "shell.execute_reply": "2023-05-19T23:01:43.672619Z"
    },
    "papermill": {
     "duration": 0.271531,
     "end_time": "2023-05-19T23:01:43.676694",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.405163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: T-shirt / Top\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(X.loc[10].values, Y.loc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49555005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:43.708147Z",
     "iopub.status.busy": "2023-05-19T23:01:43.707732Z",
     "iopub.status.idle": "2023-05-19T23:01:43.957146Z",
     "shell.execute_reply": "2023-05-19T23:01:43.956111Z"
    },
    "papermill": {
     "duration": 0.268533,
     "end_time": "2023-05-19T23:01:43.959845",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.691312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Sneaker\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(X.loc[59999].values, Y.loc[59999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700e8ed",
   "metadata": {
    "papermill": {
     "duration": 0.014284,
     "end_time": "2023-05-19T23:01:43.989012",
     "exception": false,
     "start_time": "2023-05-19T23:01:43.974728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each label matches the picture shown. This is great! \n",
    "\n",
    "Before we train the model, we need to normalize our features. This helps prevent bias in the model, because higher values are seen as more important in machine learning. Normalizing is easy here because all our features range from 0 to 255. To scale everything between 0 and 1, all we need to do is divide by 255. After that, we will use the `.head` method to make sure the values are what we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebbd8d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:44.021616Z",
     "iopub.status.busy": "2023-05-19T23:01:44.020634Z",
     "iopub.status.idle": "2023-05-19T23:01:44.140405Z",
     "shell.execute_reply": "2023-05-19T23:01:44.139515Z"
    },
    "papermill": {
     "duration": 0.13882,
     "end_time": "2023-05-19T23:01:44.142681",
     "exception": false,
     "start_time": "2023-05-19T23:01:44.003861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3    pixel4    pixel5  pixel6  pixel7    pixel8  \\\n",
       "0     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "1     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "2     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.019608   \n",
       "3     0.0     0.0     0.0  0.003922  0.007843     0.0     0.0  0.000000   \n",
       "4     0.0     0.0     0.0  0.000000  0.000000     0.0     0.0  0.000000   \n",
       "\n",
       "   pixel9  pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "1     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "2     0.0      0.0  ...  0.000000       0.0       0.0  0.117647  0.168627   \n",
       "3     0.0      0.0  ...  0.011765       0.0       0.0  0.000000  0.000000   \n",
       "4     0.0      0.0  ...  0.000000       0.0       0.0  0.000000  0.000000   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0  0.000000       0.0       0.0       0.0       0.0  \n",
       "1  0.000000       0.0       0.0       0.0       0.0  \n",
       "2  0.000000       0.0       0.0       0.0       0.0  \n",
       "3  0.003922       0.0       0.0       0.0       0.0  \n",
       "4  0.000000       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X / 255\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22afac8",
   "metadata": {
    "papermill": {
     "duration": 0.014887,
     "end_time": "2023-05-19T23:01:44.172891",
     "exception": false,
     "start_time": "2023-05-19T23:01:44.158004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Everything looks great! \n",
    "\n",
    "As you saw while we were exploring our data, we have two sets of data. The training set with 60,000 objects, and the testing set with 10,000 objects. We are going to split the training set itself into training and testing data. Then, after we train, test, and adjust the model hyperparameters iteratively until we are satisfied with our result, we will use the untouched testing set for validation. This will give us additional insight into how our model will perform on unseen data. If the accuracy results for the testing and validation sets are similar, this gives us confidence that the model will generalize well. Reducing our training set will also help the model run faster, which is useful for this learning exercise. \n",
    "\n",
    "Let's split the training set into training and testing sets with `train_test_split` from the sklearn package. We provide the features, labels, and how much of the data we want to save for testing (0.2 is 20% of the data). Let's look at the shape to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf99e195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:44.206944Z",
     "iopub.status.busy": "2023-05-19T23:01:44.205888Z",
     "iopub.status.idle": "2023-05-19T23:01:45.890777Z",
     "shell.execute_reply": "2023-05-19T23:01:45.889356Z"
    },
    "papermill": {
     "duration": 1.704749,
     "end_time": "2023-05-19T23:01:45.893556",
     "exception": false,
     "start_time": "2023-05-19T23:01:44.188807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (48000, 784)\n",
      "Training labels: (48000,)\n",
      "Testing features: (12000, 784)\n",
      "Testing labels: (12000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(\"Training features: \" + str(x_train.shape))\n",
    "print(\"Training labels: \" + str(y_train.shape))\n",
    "print(\"Testing features: \" + str(x_test.shape))\n",
    "print(\"Testing labels: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23b03f7",
   "metadata": {
    "papermill": {
     "duration": 0.015338,
     "end_time": "2023-05-19T23:01:45.925177",
     "exception": false,
     "start_time": "2023-05-19T23:01:45.909839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see we have 48,000 objects for training, and 12,000 objects for testing. 12,000 is 20% of 60,000, so this is exactly what we asked for. Everything looks ready for training.\n",
    "\n",
    "## Training the model\n",
    "\n",
    "We are finally ready to train the model. We will use the `LogisitcRegression` model from sklearn. We import it, initialize the model, and set the max iterations to 10. This is very low, but we will start with it to give us an idea of how our model will improve as we increase this.\n",
    "\n",
    "We use the `.fit` method to train the model on our training data, and finally use the `.predict` method to make predictions on our testing data. We will compare the predictions with the true labels in the next step to see how our model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90ac979f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:45.959777Z",
     "iopub.status.busy": "2023-05-19T23:01:45.958462Z",
     "iopub.status.idle": "2023-05-19T23:01:48.843408Z",
     "shell.execute_reply": "2023-05-19T23:01:48.842204Z"
    },
    "papermill": {
     "duration": 2.906299,
     "end_time": "2023-05-19T23:01:48.847682",
     "exception": false,
     "start_time": "2023-05-19T23:01:45.941383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter = 10)\n",
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred = logistic_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578d4b5",
   "metadata": {
    "papermill": {
     "duration": 0.032634,
     "end_time": "2023-05-19T23:01:48.913721",
     "exception": false,
     "start_time": "2023-05-19T23:01:48.881087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are many ways to evaluate how well a model performs. The simplest one is accuracy, which simply counts how many predictions matched the true label divided by the total number of objects being tested. So, if you got 10 correct out of 20, the accuracy would be 0.5. \n",
    "\n",
    "Precision calculates how well a model can correctly label positive samples from all the samples predicted as positive. This is measured for each class. For example, out of all the data objects that were labeled as a shirt, how many actually were a shirt? Maximizing precision is especially important when the cost of a false positive is high.\n",
    "\n",
    "Recall calculates how well a model can find all of the positive samples in the dataset. This is again measured for each class, so a good example is out of all the objects that were actually a shirt, how many were predicted as a shirt? Maximizing recall when the cost of a false negative is high is very important.\n",
    "\n",
    "We will look at all these metrics. We import them from sklearn, and we make sure that when calculating precision and recall each class is weighted with the number of its occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1dbc376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:48.970655Z",
     "iopub.status.busy": "2023-05-19T23:01:48.970228Z",
     "iopub.status.idle": "2023-05-19T23:01:49.000804Z",
     "shell.execute_reply": "2023-05-19T23:01:48.999643Z"
    },
    "papermill": {
     "duration": 0.055817,
     "end_time": "2023-05-19T23:01:49.003882",
     "exception": false,
     "start_time": "2023-05-19T23:01:48.948065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test records:\t 12000\n",
      "Accuracy count:\t\t 8797\n",
      "Acccuracy:\t\t 0.7330833333333333\n",
      "Precision:\t\t 0.7266990425245788\n",
      "Recall:\t\t\t 0.7330833333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred, normalize = True)\n",
    "accuracy_count = accuracy_score(y_test, y_pred, normalize = False)\n",
    "precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "print(\"Number of test records:\\t\", len(y_test))\n",
    "print(\"Accuracy count:\\t\\t\", accuracy_count)\n",
    "print(\"Acccuracy:\\t\\t\", accuracy)\n",
    "print(\"Precision:\\t\\t\", precision)\n",
    "print(\"Recall:\\t\\t\\t\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989149b7",
   "metadata": {
    "papermill": {
     "duration": 0.015416,
     "end_time": "2023-05-19T23:01:49.035705",
     "exception": false,
     "start_time": "2023-05-19T23:01:49.020289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We achieved an accuracy of about 73.5%. Not too bad considering we only gave it 10 iterations! Let's try increasing the iterations to 10000. We will use the same code, but will just change the iteration count. This will take much more time to run, so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19e17838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:01:49.069039Z",
     "iopub.status.busy": "2023-05-19T23:01:49.068641Z",
     "iopub.status.idle": "2023-05-19T23:08:07.419476Z",
     "shell.execute_reply": "2023-05-19T23:08:07.417806Z"
    },
    "papermill": {
     "duration": 378.405487,
     "end_time": "2023-05-19T23:08:07.456846",
     "exception": false,
     "start_time": "2023-05-19T23:01:49.051359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test records:\t 12000\n",
      "Accuracy count:\t\t 10196\n",
      "Acccuracy:\t\t 0.8496666666666667\n",
      "Precision:\t\t 0.8483412329299972\n",
      "Recall:\t\t\t 0.8496666666666667\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter = 10000)\n",
    "logistic_model.fit(x_train, y_train)\n",
    "y_pred = logistic_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred, normalize = True)\n",
    "accuracy_count = accuracy_score(y_test, y_pred, normalize = False)\n",
    "precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "\n",
    "print(\"Number of test records:\\t\", len(y_test))\n",
    "print(\"Accuracy count:\\t\\t\", accuracy_count)\n",
    "print(\"Acccuracy:\\t\\t\", accuracy)\n",
    "print(\"Precision:\\t\\t\", precision)\n",
    "print(\"Recall:\\t\\t\\t\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760edada",
   "metadata": {
    "papermill": {
     "duration": 0.020302,
     "end_time": "2023-05-19T23:08:07.510184",
     "exception": false,
     "start_time": "2023-05-19T23:08:07.489882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our results improved by about 10%! Now, let's use this existing model on our validation set that we have not used yet. We need to split that data into labels and features before we use it, and normalize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38f98589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:08:07.546598Z",
     "iopub.status.busy": "2023-05-19T23:08:07.546157Z",
     "iopub.status.idle": "2023-05-19T23:08:07.592837Z",
     "shell.execute_reply": "2023-05-19T23:08:07.591447Z"
    },
    "papermill": {
     "duration": 0.067309,
     "end_time": "2023-05-19T23:08:07.595736",
     "exception": false,
     "start_time": "2023-05-19T23:08:07.528427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_val = fashion_test_set[fashion_test_set.columns[1:]]\n",
    "X_val = X_val/255\n",
    "Y_val = fashion_test_set['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccad1a8",
   "metadata": {
    "papermill": {
     "duration": 0.015742,
     "end_time": "2023-05-19T23:08:07.627346",
     "exception": false,
     "start_time": "2023-05-19T23:08:07.611604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that our data is split, let's use the model to make predictions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba0f1427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-19T23:08:07.660910Z",
     "iopub.status.busy": "2023-05-19T23:08:07.660469Z",
     "iopub.status.idle": "2023-05-19T23:08:07.750515Z",
     "shell.execute_reply": "2023-05-19T23:08:07.748955Z"
    },
    "papermill": {
     "duration": 0.112279,
     "end_time": "2023-05-19T23:08:07.755385",
     "exception": false,
     "start_time": "2023-05-19T23:08:07.643106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test records:\t 10000\n",
      "Accuracy count:\t\t 8500\n",
      "Acccuracy:\t\t 0.85\n",
      "Precision:\t\t 0.8484116705434779\n",
      "Recall:\t\t\t 0.85\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = logistic_model.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred_val, normalize = True)\n",
    "accuracy_count = accuracy_score(Y_val, y_pred_val, normalize = False)\n",
    "precision = precision_score(Y_val, y_pred_val, average = 'weighted')\n",
    "recall = recall_score(Y_val, y_pred_val, average = 'weighted')\n",
    "\n",
    "print(\"Number of test records:\\t\", len(y_pred_val))\n",
    "print(\"Accuracy count:\\t\\t\", accuracy_count)\n",
    "print(\"Acccuracy:\\t\\t\", accuracy)\n",
    "print(\"Precision:\\t\\t\", precision)\n",
    "print(\"Recall:\\t\\t\\t\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136e47f",
   "metadata": {
    "papermill": {
     "duration": 0.032785,
     "end_time": "2023-05-19T23:08:07.822474",
     "exception": false,
     "start_time": "2023-05-19T23:08:07.789689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our results are remarkably similar to the testing data we used before. This is good news! We can be confident that our model will achieve about 85% accuracy on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6868ff",
   "metadata": {
    "papermill": {
     "duration": 0.015857,
     "end_time": "2023-05-19T23:08:07.860260",
     "exception": false,
     "start_time": "2023-05-19T23:08:07.844403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this exercise, we explored the fashion MNIST dataset, and used it to create a logistic regression model that predicts clothing type based on a 28x28 pixel gray image. We achieved an accuracy of about 85% with both our testing and validation data set. \n",
    "\n",
    "This exercise helped us understand how to use the logistic regression model from sklearn and the essential steps in every machine learning process. We also saw the importance of setting appropriate hyperparameters, which in this case was the max iterations allowed. This is just a starting point in learning how to improve this model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 419.173721,
   "end_time": "2023-05-19T23:08:09.001659",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-19T23:01:09.827938",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
